[
["non-stationary-time-series-hidden-markov-model.html", "Exercise 4 Non stationary time series - Hidden Markov Model 4.1 Fit a best HMM for the May Lees Ferry streamflow 4.2 Generate 250 simulations from the fitted HMM 4.3 Boxplot the resulting statistics 4.4 Fit a GLM for the state series 4.5 Use the state GLM to simulate flows from the component distribution", " Exercise 4 Non stationary time series - Hidden Markov Model Another way to simulate a time series is using Hidden Markov Model (Markov Chain + resampling). First, we load the libraries, streamflow data, and functions via R markdown (attached at the end of the document). # libraries libr=c(&quot;HiddenMarkov&quot;,&quot;ggplot2&quot;,&quot;data.table&quot;,&quot;ggthemes&quot;, &quot;magrittr&quot;,&quot;sm&quot;,&quot;moments&quot;,&quot;MASS&quot;,&quot;leaps&quot;) options(warn=1) suppressPackageStartupMessages(lapply(libr, require, character.only = TRUE)) ## Load flow data flow = read.table( &quot;http://civil.colorado.edu/~balajir/CVEN6833/HWs/HW-3-2018/LeesFerry-monflows-1906-2016.txt&quot;) flow = flow[,2:13] %&gt;% `rownames&lt;-`(flow[,1]) %&gt;% setNames(.,c(&quot;jan&quot;,&quot;feb&quot;,&quot;mar&quot;,&quot;apr&quot;,&quot;may&quot;,&quot;jun&quot;, &quot;jul&quot;,&quot;aug&quot;,&quot;sep&quot;,&quot;oct&quot;,&quot;nov&quot;,&quot;dec&quot;)) %&gt;% {./10^6} # convert AF to MAF x = flow$may ## select the May month flows 4.1 Fit a best HMM for the May Lees Ferry streamflow The code below fits HMM models of orders 2 through 6 and calculates the AIC for each. The best order is the one with the least value of AIC. ## Fit HMM models of orders 2 through 6. Obtain the AIC for each ## Best order is the one with the least value of AIC. family &lt;- &quot;gamma&quot; # underlying distribution for hmm discrete &lt;- FALSE aic1=c() for(imodel in 2:6){ m &lt;- imodel #model order to fit stationary &lt;- F # use a stationary distribution of mixtures # different initial condition types when family == &quot;norm&quot; ic &lt;- &quot;same.sd&quot;#c(&quot;same.sd&quot;,&quot;same.both&quot;,&quot;both.diff&quot;) fd.name &lt;- ifelse(family == &quot;norm&quot;, &quot;normal&quot;, family) Pi &lt;- Pi_init(m) # T.P.M. delta &lt;- delta_init(m) pars &lt;- get.named.parlist(x, m, fd.name, lower=.0, ic)#,start=list(shape1=2,shape2=2)) # set up the model hmm &lt;- dthmm(x, Pi=Pi, delta=delta, family, pars, nonstat=!stationary, discrete = discrete) sink(&quot;p.4.hmm.fit&quot;) if(imodel &lt; 2){ hmm &lt;- BaumWelch(hmm, bwcontrol(maxiter = 1000, posdiff=TRUE,converge = expression(diff &gt; tol))) } else { hmm &lt;- BaumWelch(hmm, bwcontrol(maxiter = 1000, tol = 1e-08)) } sink() # get the hidden states from the fitted model # Global decoding. To get the probability of being in a state: hmm$u decoding &lt;- Viterbi(hmm) # get AIC aic &lt;- AIC(hmm) aic1=c(aic1,aic) } We select the HMM with the lowest AIC. In this case, this happens to be of order 2. We rerun the HMM for best order (m=2) and generate the state sequence (decoding) resulting from it. The model summary is also attached. ## Get the best order bestorder = order(aic1)[1] +1 ## Fit the model for this best order m &lt;- bestorder #model order to fit stationary &lt;- F # use a stationary distribution of mixtures # different initial condition types when family == &quot;norm&quot; ic &lt;- &quot;same.sd&quot;#c(&quot;same.sd&quot;,&quot;same.both&quot;,&quot;both.diff&quot;) fd.name &lt;- ifelse(family == &quot;norm&quot;, &quot;normal&quot;, family) Pi &lt;- Pi_init(m) # T.P.M. delta &lt;- delta_init(m) pars &lt;- get.named.parlist(x, m, fd.name, lower=.0, ic)#,start=list(shape1=2,shape2=2)) # set up the model hmm &lt;- dthmm(x, Pi=Pi, delta=delta, family, pars, nonstat=!stationary, discrete = discrete) sink(&quot;p.4.best.hmm&quot;) hmm &lt;- BaumWelch(hmm, bwcontrol(maxiter = 1000, tol = 1e-08)) sink() # end hidding output decoding &lt;- Viterbi(hmm) print(summary(hmm)) ## $delta ## [1] 1.000000e+00 1.165686e-105 ## ## $Pi ## [,1] [,2] ## [1,] 0.7046161 0.2953839 ## [2,] 0.3414245 0.6585755 ## ## $nonstat ## [1] TRUE ## ## $distn ## [1] &quot;gamma&quot; ## ## $pm ## $pm$rate ## [1] 4.062194 2.974821 ## ## $pm$shape ## [1] 15.20308 6.99202 ## ## ## $discrete ## [1] FALSE ## ## $n ## [1] 111 cat(&#39;Model order:&#39;,m,&#39;\\n&#39;) ## Model order: 2 p &lt;- ggplot_stationary_hmm(hmm,.5) print(p) ## Warning: Removed 1 rows containing missing values (geom_bar). state.1=ifelse(decoding==1,2.5,NA) state.2=ifelse(decoding==2,0.5,NA) plot(flow$may-mean(flow$may)+1.5,type=&quot;l&quot;,ylab=&quot;&quot;, main=&quot;Modified May flows and states (supperposed)&quot;) points(state.2,col=&#39;blue&#39;) points(state.1,col=&#39;red&#39;) legend(&quot;topright&quot;,legend=c(&quot;state 1&quot;,&quot;state 2&quot;),col=c(&quot;red&quot;,&quot;blue&quot;),pch=1) 4.2 Generate 250 simulations from the fitted HMM This involves generating the state sequence from the transition probability matrix and resampling flows from the corresponding component distribution. # Now simulate # First simulate a sequence of states from the TPM # simulate from the transition probability N = length(x) nsim = 250 nprob = length(decoding[decoding == 1])/N delta1=c(nprob,1-nprob) #stationary probability zsim = mchain(NULL,hmm$Pi,delta=delta1) may.sim = matrix(0,nrow=nsim,ncol=N) # Points where May PDF is evaluated xeval=seq(min(flow$may)-0.25*sd(flow$may), max(flow$may)+0.25*sd(flow$may),length=100) sim.pdf=matrix(0,nrow=nsim,ncol=100) # Array to store May simulated PDF may.stat=matrix(NA,ncol = 6,nrow = nsim) # year statistics colnames(may.stat) = c(&quot;mean&quot;,&quot;stdev&quot;,&quot;min&quot;,&quot;max&quot;,&quot;skew&quot;,&quot;cor&quot;) for(isim in 1:nsim){ zsim = simulate(zsim,nsim=N) ## now simulate the flows from the corresponding PDF flowsim = c() for(i in 1:N){ if(zsim$mc[i] == 1)xx=rgamma(1,shape=hmm$pm$shape[1], scale=1/hmm$pm$rate[1]) if(zsim$mc[i] == 2)xx=rgamma(1,shape=hmm$pm$shape[2], scale=1/hmm$pm$rate[2]) flowsim=c(flowsim,xx) } may.sim[isim,]=flowsim sim.pdf[isim,]=sm.density(flowsim,eval.points=xeval, display=&quot;none&quot;)$estimate # fill statistics may.stat[isim,&quot;mean&quot;]=mean(flowsim) may.stat[isim,&quot;max&quot;]=max(flowsim) may.stat[isim,&quot;min&quot;]=min(flowsim) may.stat[isim,&quot;stdev&quot;]=sd(flowsim) may.stat[isim,&quot;skew&quot;]=skewness(flowsim) may.stat[isim,&quot;cor&quot;]=cor(flowsim[-N],flowsim[2:N]) } The statistics from the historical data is added in the first row of the statistics matrix. # Compute statistics from the historical data. obs=1:6 obs[1]=mean(flow$may) obs[2]=sd(flow$may) obs[3]=min(flow$may) obs[4]=max(flow$may) obs[5]=skewness(flow$may) obs[6]=cor(flow$may[-N],flow$may[2:N]) # bind the stats of the historic data at the top.. may.stat=rbind(obs,may.stat) 4.3 Boxplot the resulting statistics We include the mean, variance, skew, lag-1 correlation, minimum, maximum and PDF from the simulations with the corresponding values from the historical data plotted on them. # function to plot boxplots with the structure: hist. in first row plot.bp = function(matrix,name){ xmeans=as.matrix(matrix) n=length(xmeans[,1]) xmeans1=as.matrix(xmeans[2:n,]) #the first row is the original data xs=1:12 zz=boxplot(split(xmeans1,col(xmeans1)), plot=F, cex=1.0) zz$names=rep(&quot;&quot;,length(zz$names)) z1=bxp(zz,ylim=range(xmeans),xlab=&quot;&quot;,ylab=&quot;&quot;,cex=1.00) points(z1,xmeans[1,],pch=16, col=&quot;red&quot;) lines(z1,xmeans[1,],pch=16, col=&quot;gray&quot;) title(main=name) } par(mfrow=c(2,3)) plot.bp(may.stat[,&quot;mean&quot;],&quot;Mean&quot;) plot.bp(may.stat[,&quot;stdev&quot;],&quot;Standard Deviation&quot;) plot.bp(may.stat[,&quot;min&quot;],&quot;Min&quot;) plot.bp(may.stat[,&quot;max&quot;],&quot;Max&quot;) plot.bp(may.stat[,&quot;skew&quot;],&quot;Skews&quot;) plot.bp(may.stat[,&quot;cor&quot;],&quot;Lag-1 correlation&quot;) xdensityorig = flow$may %&gt;% sm.density(.,eval.points=xeval,display=&quot;none&quot;) %&gt;% .$estimate plot.pdf = function(eval,histPDF,simPDF){ xeval = eval plot(xeval,histPDF,pch=&quot;.&quot;,col=&quot;red&quot;,ylim=range(simPDF,histPDF), xlab=&quot;&quot;,ylab = &quot;&quot;) for(i in 1:nsim)lines(xeval,simPDF[i,],col=&#39;lightgrey&#39;,lty=3) lines(xeval,histPDF,lwd=3,col=&quot;red&quot;) title(main=&quot;Historical vs. simulated PDF&quot;) } plot.pdf(xeval,xdensityorig,sim.pdf) The model is able to represent accurately all statistics, including lag-1 correlation. 4.4 Fit a GLM for the state series Instead of simulating the streamflow from a “static” state sequence simulation, the goal is to simulate the state as a prediction from a best logistic GLM. The uncertainty is added choosing random values and comparing them to the initial probability (p1 / p2) of being in a particular state. enso=read.table(&quot;C:/Users/alexb/Google Drive/CVEN 6833 ADAT/zz Homeworks/HW3/enso.txt&quot;) amo=read.table(&quot;C:/Users/alexb/Google Drive/CVEN 6833 ADAT/zz Homeworks/HW3/amo.txt&quot;) pdo=read.table(&quot;C:/Users/alexb/Google Drive/CVEN 6833 ADAT/zz Homeworks/HW3/pdo.txt&quot;) X = data.frame(decoding[-N]-1,enso[-N,],amo[-N,],pdo[-N,]) colnames(X) = c(&quot;ts1&quot;,&quot;enso&quot;,&quot;amo&quot;,&quot;pdo&quot;) Y = decoding[-1]-1 links = c(&quot;logit&quot;, &quot;probit&quot;, &quot;cauchit&quot;,&quot;log&quot;,&quot;cloglog&quot;) # potential links comb=leaps(X,Y, nbest=40,method=&quot;adjr2&quot;)$which # all combinations of cov. aic &lt;- matrix(1e6,ncol=length(links),nrow = length(comb[,1])) colnames(aic) = links[1:length(links)] for(k in 1:length(comb[,1])){ # try every link f. with every comb. xx = X[,comb[k,]] %&gt;% as.data.frame(.) for(i in 1:length(links)){ zz=try(glm(Y ~ ., data=xx, family = binomial(link=links[i]), maxit=500),silent=TRUE) if(class(zz)[1]!=&quot;try-error&quot;)aic[k,i]=zz$aic[1] } } head(aic) ## logit probit cauchit log cloglog ## [1,] 125.3869 125.3869 125.3869 125.3869 125.3869 ## [2,] 146.9211 146.8480 147.3203 147.6516 147.2601 ## [3,] 148.3173 148.4183 147.6240 148.3154 148.2197 ## [4,] 151.5616 151.5576 151.5843 151.5754 151.5692 ## [5,] 124.8050 124.6801 125.4507 1000000.0000 125.1181 ## [6,] 125.5837 125.6196 125.6204 1000000.0000 125.7381 index = which(aic == min(aic), arr.ind = TRUE) # select min. AIC print( sprintf(&quot;Choosing the GLM which minimizes AIC for binomial family: %s link function and %s covariates&quot;,links[index[,&quot;col&quot;]], paste(colnames(X)[comb[index[,&quot;row&quot;],]],collapse = &#39;, &#39;))) ## [1] &quot;Choosing the GLM which minimizes AIC for binomial family: probit link function and ts1, amo covariates&quot; state.glm = glm(Y ~ ., data=X[,comb[index[,&quot;row&quot;],]], family = binomial(link=links[index[,&quot;col&quot;]])) summary(state.glm) # Model selected ## ## Call: ## glm(formula = Y ~ ., family = binomial(link = links[index[, &quot;col&quot;]]), ## data = X[, comb[index[, &quot;row&quot;], ]]) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.7872 -0.7333 -0.5345 0.8427 1.9937 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.8180 0.1756 -4.658 3.19e-06 *** ## ts1 1.2820 0.2683 4.779 1.76e-06 *** ## amo 0.9847 0.5931 1.660 0.0969 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 148.06 on 109 degrees of freedom ## Residual deviance: 118.68 on 107 degrees of freedom ## AIC: 124.68 ## ## Number of Fisher Scoring iterations: 4 ENSO and PDO covariates resulted to be insignificant for the logistic regression, even if several laggings from the original data have been tried. 4.5 Use the state GLM to simulate flows from the component distribution With the fitted values from the logistic regression, we calculate first the probabilities (p1, p2) of each state. These are used to generate a random initial state and simulate the rest of the state sequence. Depending on the simulated sequence, a random gamma value is taken from either state 1 or state 2, creating a new streamflow time series, with the same length as the original data. The simulation is repeated 250 to generate statistics and ensemble PDF. X.new = X[,comb[index[,&quot;row&quot;],]] p1 = 1 - sum(round(state.glm$fitted.values))/length(state.glm$fitted.values) state = 1:N # init. state state.p1 = 1:nsim # store p1 for debugging may.sim.glm = matrix(0,nrow=nsim,ncol=N) sim.pdf.glm = matrix(0,nrow=nsim,ncol=100) # Array to store May simulated PDF may.stat.glm=matrix(NA,ncol = 6,nrow = nsim) # statistics colnames(may.stat.glm) = c(&quot;mean&quot;,&quot;stdev&quot;,&quot;min&quot;,&quot;max&quot;,&quot;skew&quot;,&quot;cor&quot;) # simulation for(isim in 1:nsim){ # for(j in 2:N)state[j]=round(predict(state.glm,newdata = data.frame(ts1=state[j-1],amo = amo[j-1,1]))) for(j in 1:N){ if(j==1){ state[1]=ifelse(runif(1)&lt;p1,1,2) }else{ state[j]=ifelse(state.glm$fitted.values[j-1]&lt;runif(1),1,2) } if(state[j]==1){ may.sim.glm[isim,j]=rgamma(1,shape = hmm$pm$shape[1],hmm$pm$rate[1]) }else{ may.sim.glm[isim,j]=rgamma(1,shape = hmm$pm$shape[2],hmm$pm$rate[2]) } } state.p1[isim] = 1 - sum((state-1))/length(state) sim.pdf.glm[isim,]=sm.density(may.sim.glm[isim,], eval.points=xeval,display=&quot;none&quot;)$estimate # fill statistics may.stat.glm[isim,&quot;mean&quot;]=mean(may.sim.glm[isim,]) may.stat.glm[isim,&quot;max&quot;]=max(may.sim.glm[isim,]) may.stat.glm[isim,&quot;min&quot;]=min(may.sim.glm[isim,]) may.stat.glm[isim,&quot;stdev&quot;]=sd(may.sim.glm[isim,]) may.stat.glm[isim,&quot;skew&quot;]=skewness(may.sim.glm[isim,]) may.stat.glm[isim,&quot;cor&quot;]=cor(may.sim.glm[isim,-N],may.sim.glm[isim,2:N]) } # bind the stats of the historic data at the top.. may.stat.glm=rbind(obs,may.stat.glm) par(mfrow=c(2,3)) plot.bp(may.stat.glm[,&quot;mean&quot;],&quot;Mean&quot;) plot.bp(may.stat.glm[,&quot;stdev&quot;],&quot;Standard Deviation&quot;) plot.bp(may.stat.glm[,&quot;min&quot;],&quot;Min&quot;) plot.bp(may.stat.glm[,&quot;max&quot;],&quot;Max&quot;) plot.bp(may.stat.glm[,&quot;skew&quot;],&quot;Skews&quot;) plot.bp(may.stat.glm[,&quot;cor&quot;],&quot;Lag-1 correlation&quot;) plot.pdf(xeval,xdensityorig,sim.pdf.glm) Functions from lib.R: # source functions # takend from &quot;http://civil.colorado.edu/~balajir/CVEN6833/R-sessions/session3/files-4HW3/lib.R&quot; Pi_init &lt;- function(n,type=&#39;uniform&#39;){ matrix(rep(1/n,n^2),n)} delta_init &lt;- function(n, type=&#39;uniform&#39;){ d &lt;- rnorm(n)^2 d/sum(d)} ntile.ts &lt;- function(x, n, limit.type = &#39;prob&#39;, tie = 1, altobs = NULL ){ # returns an integer vector corresponding to n states broken by equal # probability or equal distance # limit &lt;- if(limit.type == &#39;prob&#39;) quantile(x,seq(0,1,1/n)) else if(limit.type == &#39;equal&#39;) seq(min(x),max(x),by=diff(range(x))/n) if(!is.null(altobs)) limit &lt;- quantile(altobs,seq(0,1,1/n)) b &lt;- integer(length(x)) for(i in 1:(n+1)){ filter &lt;- if(tie == 1) x &gt;= limit[i] &amp; x &lt;= limit[i+1] else x &gt; limit[i] &amp; x &lt;= limit[i+1] #only need to set the 1&#39;s because b is already 0&#39;s b[filter] &lt;- as.integer(i-1) } if(class(x) == &#39;ts&#39;) return(ts(b,start=start(x),end=end(x))) else return(b) } get.named.parlist &lt;- function(x,m,dist,ic,...){ require(MASS) fit &lt;- fitdistr(x,dist,...) np &lt;- length(fit$estimate) pars &lt;- vector(&#39;list&#39;,np) names(pars) &lt;- names(fit$estimate) init &lt;- lapply(fit$estimate,max) names(init) &lt;- names(fit$estimate) for(j in 1:m){ #print(j) #browser() #browser() this.fit &lt;- fitdistr(x[ntile.ts(x,m) == (j-1)],dist,init,...) #for(k in 1:np) # pars[[k]][j] &lt;- this.fit$estimate[k] for(k in 1:np) pars[[k]][j] &lt;- fit$estimate[k] if(dist == &#39;normal&#39;){ if(ic == &#39;same.both&#39;){ pars[[k]][j] &lt;- mean(x) pars[[k]][j] &lt;- sd(x) } else if( ic == &#39;same.sd&#39;){ pars[[k]][j] &lt;- mean(x[ntile.ts(x,m) == (j-1)]) pars[[k]][j] &lt;- sd(x) }else{ pars[[k]][j] &lt;- mean(x[ntile.ts(x,m) == (j-1)]) pars[[k]][j] &lt;- sd(x[ntile.ts(x,m) == (j-1)]) } } } pars } AIC.dthmm &lt;- function(x){ ## Return the Akaieke Information criterion value for a fitted discrete ## time hidden markov model from the HiddenMarkov package # Model order m &lt;- length(x$delta) # Log Liklihood value LL &lt;- x$LL # number of parameters p &lt;- m+m^2 # AIC -2*LL + 2*p } ggplot_stationary_hmm &lt;- function(x,binwidth=NULL,res=1000,cols=NULL,...){ m &lt;- length(x$delta) dens &lt;- matrix(0,nrow=m+1,ncol=res) r &lt;- extendrange(x$x,f=.05) xrange &lt;- seq(r[1],r[2],len=res) delta &lt;- statdist(x$Pi) if(is.null(binwidth)) binwidth &lt;- diff(range(x$x))/8 for(i in 1:m){ if(x$distn == &#39;gamma&#39;){ dens[i,] &lt;- delta[i]*dgamma(xrange,shape=x$pm$shape[i],rate=x$pm$rate[i]) }else if(x$distn == &#39;norm&#39;){ dens[i,] &lt;- delta[i]*dnorm(xrange,mean=x$pm$mean[i],sd=x$pm$sd[i]) }else{ stop(&#39;Distribution not supported&#39;) } dens[m+1,] &lt;- dens[m+1,] + dens[i,] } p &lt;- ggplot()+ geom_histogram(data=data.frame(x=as.vector(x$x)),aes(x=x,y=..density..), binwidth=binwidth,fill=&#39;white&#39;,color=&#39;black&#39;)+ theme_bw() dt &lt;- data.table(x=numeric(0),y=numeric(0), state=integer(0)) for(i in 1:m) dt &lt;- rbind(dt, data.table(x=xrange,y=dens[i,], state=i)) dt$state &lt;- factor(dt$state) p &lt;- p + geom_line(data=dt,aes(x=x,y=y,color=state)) + geom_line(data=data.frame(x=xrange,y=dens[m+1,]),aes(x=x,y=y),color=&#39;black&#39;,size=1) + scale_color_tableau() + scale_x_continuous(limits=r) p } statdist &lt;- function(tpm){ m &lt;- nrow(tpm) ones &lt;- rbind(rep(1,m)) I &lt;- diag(rep(1,m)) U &lt;- matrix(rep(1,m^2),m) as.vector(ones %*% solve(I - tpm + U)) } "]
]
