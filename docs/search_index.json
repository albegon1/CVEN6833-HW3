[
["index.html", "CVEN 6833 - Homework 3 Topics", " CVEN 6833 - Homework 3 Alex Belenguer Topics Parametric/Nonparametric Time Series Hidden Markov Model Wavelet Spectral Analysis Extreme Value Time Series Copulas "],
["seasonal-ar1-model.html", "Exercise 1 Seasonal AR(1) model 1.1 Generate 250 simulations each of same length as the historical data. 1.2 Plot statistics from simulations 1.3 Replace the simulation of the errors (or innovations) from Normal to Gamma", " Exercise 1 Seasonal AR(1) model Fit a seasonal AR(1) model – i.e., nonstationary time series model to the monthly Colorado River Flow at Lees Ferry. 1.1 Generate 250 simulations each of same length as the historical data. # Load libraries libr=c(&quot;magrittr&quot;,&quot;sm&quot;,&quot;stats&quot;,&quot;moments&quot;) options(warn=1) suppressPackageStartupMessages(lapply(libr, require, character.only = TRUE)) # import and set up flow data flow = read.table( &quot;http://civil.colorado.edu/~balajir/CVEN6833/HWs/HW-3-2018/LeesFerry-monflows-1906-2016.txt&quot;) flow = flow[,2:13] %&gt;% `rownames&lt;-`(flow[,1]) %&gt;% setNames(.,c(&quot;jan&quot;,&quot;feb&quot;,&quot;mar&quot;,&quot;apr&quot;,&quot;may&quot;,&quot;jun&quot;, &quot;jul&quot;,&quot;aug&quot;,&quot;sep&quot;,&quot;oct&quot;,&quot;nov&quot;,&quot;dec&quot;)) %&gt;% {./10^6} # convert AF to MAF head(flow,n=1L) # show values ## jan feb mar apr may jun jul aug ## 1906 0.244314 0.292534 0.678174 1.20464 3.635101 5.014167 2.95046 1.605086 ## sep oct nov dec ## 1906 1.503159 0.739807 0.503006 0.353312 tail(flow,n=1L) ## jan feb mar apr may jun jul ## 2016 0.360703 0.448837 0.67914 1.099567 2.967581 3.910287 1.342044 ## aug sep oct nov dec ## 2016 0.609946 0.485507 0.546633 0.426289 0.345163 flow$year = rowSums(flow) # add year in 13th column par(mfrow=c(4,3)) # plot histogram and density of monthly flow for(i in 1:12){ hist(flow[,i], freq=FALSE, main = colnames(flow)[i],xlab = &quot;&quot;,ylab = &quot;&quot;) sm.density(flow[,i], add=TRUE) } par(mfrow=c(1,1)) # plot histogram and density of anual flow hist(flow[,13], freq=FALSE, main = colnames(flow)[13],xlab = &quot;&quot;) sm.density(flow[,13], add=TRUE) The seasonal AR model is fitted using the Thomas Fiering coefficients. The anual flow AR model is fitted using stats::arima. # Get the parameters of the Thomas Fiering Model (12 models, 1 for each transition) coef1 = coef2 = rep(0,length.out = 12) coef1[1] = cor(flow[-1,&quot;jan&quot;],flow[-111,&quot;dec&quot;]) # jan - dec coef2[1] = sqrt((var(flow[,1])) * (1. - coef1[1]*coef1[1])) for(i in 2:12){ # remaining month pairs coef1[i] = cor(flow[,i],flow[,i-1]) coef2[i] = sqrt((var(flow[,i])) * (1. - coef1[i]*coef1[i])) } # The anual flow is modeled using single AR(1) model ar.year=ar(flow$year,order.max = 1) #AR order 1, MA The 12 pairs of the TF coefficients are used to run 250 simulations (synthetic values) that will populate the statistics for the models. For the anual flow model, the simulations are obtained via stats::arima.sim. The random gamma values are related to the normal following the relationship explained in the thread below: https://stats.stackexchange.com/questions/37461/the-relationship-between-the-gamma-distribution-and-the-normal-distribution innovation = &quot;Normal&quot; # defines nature of innovations: &quot;Normal&quot; or &quot;Gamma&quot; # parameters for equivalent gamma distribution # N(x;0,s) ~ lim(a -&gt; +inf) G((a-1)*sqrt(1/a)*s;a,sqrt(1/a)*s) a=5 sm=1 #sd for monthly innovations sy=sd(flow$year) #sd for monthly innovations # peak density for each month peak=rep(NA,12) for(i in 1:12){ aux=sm.density(flow[,i],display=&quot;none&quot;) peak[i]=aux$eval.points[which.max(aux$estimate)]*1.5 } # Simulations (innovation defines st. distribution of error) nsim=250 # number of simulations nyrs=length(flow[,1]) # years armean=matrix(0,nsim,12) #matrices that store the statistics arstdev=matrix(0,nsim,12) arcor=matrix(0,nsim,12) arskw=matrix(0,nsim,12) armax=matrix(0,nsim,12) armin=matrix(0,nsim,12) ar.year.stat=matrix(NA,ncol = 6,nrow = nsim) # year statistics colnames(ar.year.stat) = c(&quot;mean&quot;,&quot;stdev&quot;,&quot;min&quot;,&quot;max&quot;,&quot;skew&quot;,&quot;cor&quot;) # Points where May PDF is evaluated xeval=seq(min(flow$may)-0.25*sd(flow$may), max(flow$may)+0.25*sd(flow$may),length=100) simpdf=matrix(0,nrow=nsim,ncol=100) # Array to store May simulated PDF # Points where anual PDF is evaluated yeval=seq(min(flow$year)-0.25*sd(flow$year), max(flow$year)+0.25*sd(flow$year),length=100) year.pdf=matrix(0,nrow=nsim,ncol=100) # Array to store anual simulated PDF for(k in 1:nsim){ nmons=nyrs*12 #number of values to be generated xsim=1:nmons r=sample(1:nyrs,1) xsim[1]=flow[r,1] # Starting point for sim xprev=xsim[1] for(i in 2:nmons){ j=i %% 12 if(j == 0) j=12 j1=j-1 if(j == 1) j1=12 x1=xprev-ifelse(innovation==&quot;Normal&quot;,mean(flow[,j1]),peak[j1]) x2=coef2[j]*ifelse(innovation==&quot;Normal&quot;,rnorm(1,0,1), rgamma(1,shape=a,scale=sqrt(1/a)*sm)-(a-1)*sqrt(1/a)*sm) xsim[i]=mean(flow[,j]) + x1*coef1[j] + x2 xprev=xsim[i] } #Store simulated values in matrix form, get May values and PDF simdismon=matrix(xsim,ncol = 12, byrow = TRUE) # filled by row maysim = simdismon[,5] # Synthetic values for May simpdf[k,]=sm.density(maysim,eval.points=xeval,display=&quot;none&quot;)$estimate # Fill statistics for each month for(j in 1:12){ armean[k,j]=mean(simdismon[,j]) armax[k,j]=max(simdismon[,j]) armin[k,j]=min(simdismon[,j]) arstdev[k,j]=sd(simdismon[,j]) arskw[k,j]=skewness(simdismon[,j]) } arcor[k,1]=cor(simdismon[-nyrs,12],simdismon[2:nyrs,1]) #cor dec-jan for(j in 2:12){ # rest of pairs j1=j-1 arcor[k,j]=cor(simdismon[,j],simdismon[,j1]) } # anual flow simulations if(innovation==&quot;Normal&quot;){ ar.year.sim = arima.sim(n = nyrs, list(ar = ar.year$ar), sd = sqrt(ar.year$var.pred)) + mean(flow$year) }else{ ar.year.sim = arima.sim(n = nyrs, list(ar = ar.year$ar), rand.gen = function(n, ...) rgamma(n,shape=a, scale=sqrt(1/a)*sy)-(a-1)*sqrt(1/a)*sy) + yeval[which.max(year.density)]*0.85 } # Get anual PDF year.pdf[k,]=sm.density(ar.year.sim,eval.points= yeval,display=&quot;none&quot;)$estimate # Calculate statistics ar.year.stat[k,&quot;mean&quot;]=mean(ar.year.sim) ar.year.stat[k,&quot;max&quot;]=max(ar.year.sim) ar.year.stat[k,&quot;min&quot;]=min(ar.year.sim) ar.year.stat[k,&quot;stdev&quot;]=sd(ar.year.sim) ar.year.stat[k,&quot;skew&quot;]=skewness(ar.year.sim) ar.year.stat[k,&quot;cor&quot;]=cor(ar.year.sim[-nyrs],ar.year.sim[2:nyrs]) } The statistics from the synthetic values and the historical data are bound in the same matrix. # Compute statistics from the historical data. obsmean=1:12 obsstdev=1:12 obscor=1:12 obsskw=1:12 obsmax=1:12 obsmin=1:12 for(i in 1:12){ obsmax[i]=max(flow[,i]) obsmin[i]=min(flow[,i]) obsmean[i]=mean(flow[,i]) obsstdev[i]=sd(flow[,i]) obsskw[i]=skewness(flow[,i]) } obscor[1]= cor(flow[-nyrs,12], flow[2:nyrs,1]) for(i in 2:12){ i1=i-1 obscor[i]=cor(flow[,i], flow[,i1]) } # bind the stats of the historic data at the top.. armean=rbind(obsmean,armean) arstdev=rbind(obsstdev,arstdev) arskw=rbind(obsskw,arskw) arcor=rbind(obscor,arcor) armax=rbind(obsmax,armax) armin=rbind(obsmin,armin) # anual flow binding year.stat=c(mean(flow$year),sd(flow$year),min(flow$year), max(flow$year),skewness(flow$year), cor(flow$year[-nyrs],flow$year[2:nyrs])) ar.year.stat = rbind(year.stat,ar.year.stat) 1.2 Plot statistics from simulations Create boxplots of annual and monthly, mean, variance, skew, lag-1 correlation, minimum, maximum and PDFs of May and annual flows. Comment on what you observe and also on why some of the monthly statistics are not captured. # function to plot boxplots with the structure: hist. in first row plot.bp = function(matrix,name){ xmeans=as.matrix(matrix) n=length(xmeans[,1]) xmeans1=as.matrix(xmeans[2:n,]) #the first row is the original data xs=1:12 zz=boxplot(split(xmeans1,col(xmeans1)), plot=F, cex=1.0) zz$names=rep(&quot;&quot;,length(zz$names)) z1=bxp(zz,ylim=range(xmeans),xlab=&quot;&quot;,ylab=&quot;&quot;,cex=1.00) points(z1,xmeans[1,],pch=16, col=&quot;red&quot;) lines(z1,xmeans[1,],pch=16, col=&quot;gray&quot;) title(main=name) } The plots for the statistics of the simulated time series (shown as boxplots) vs. the historical data (shown as points and lines) are reproduced below: par(mfrow=c(3,2)) plot.bp(armean,&quot;Mean&quot;) plot.bp(arstdev,&quot;Standard Deviation&quot;) plot.bp(armin,&quot;Min&quot;) plot.bp(armax,&quot;Max&quot;) plot.bp(arskw,&quot;Skews&quot;) plot.bp(arcor,&quot;Lag-1 correlation&quot;) The model proficiently captures the mean and max values. A fair fit is obtained with the standard deviation. However, the normality of the innovations results in a poor fit of minimum values and skews. The anual statistics are similarly represented below: par(mfrow=c(2,3)) plot.bp(ar.year.stat[,&quot;mean&quot;],&quot;Mean&quot;) plot.bp(ar.year.stat[,&quot;stdev&quot;],&quot;Standard Deviation&quot;) plot.bp(ar.year.stat[,&quot;min&quot;],&quot;Min&quot;) plot.bp(ar.year.stat[,&quot;max&quot;],&quot;Max&quot;) plot.bp(ar.year.stat[,&quot;skew&quot;],&quot;Skews&quot;) plot.bp(ar.year.stat[,&quot;cor&quot;],&quot;Lag-1 correlation&quot;) The best fitting occurs for mean, sd, and correlation. Min, max and skew hardly contain historical values within the 25th/75th percentile limits. The simulated May PDF vs. the historical May PDF is plotted at 100 points. xdensityorig = flow$may %&gt;% sm.density(.,eval.points=xeval,display=&quot;none&quot;) %&gt;% .$estimate plot.pdf = function(eval,histPDF,simPDF){ xeval = eval plot(xeval,histPDF,pch=&quot;.&quot;,col=&quot;red&quot;,ylim=range(simPDF,histPDF), xlab=&quot;&quot;,ylab = &quot;&quot;) for(i in 1:nsim)lines(xeval,simPDF[i,],col=&#39;lightgrey&#39;,lty=3) lines(xeval,histPDF,lwd=3,col=&quot;red&quot;) title(main=&quot;Historical vs. simulated PDF&quot;) } plot.pdf(xeval,xdensityorig,simpdf) The bimodal historical May PDF is not captured by the simulations due to the Normal nature of the innovations. The simulated vs. historical anual flow PDF is similarly compared. year.density = flow$year %&gt;% sm.density(.,eval.points=yeval, display=&quot;none&quot;) %&gt;% .$estimate plot.pdf(yeval,year.density,year.pdf) 1.3 Replace the simulation of the errors (or innovations) from Normal to Gamma The simulation code chunks are rerun via r markdown code with innovation = “Gamma”. innovation=&quot;Gamma&quot; par(mfrow=c(3,2)) plot.bp(armean,&quot;Mean&quot;) plot.bp(arstdev,&quot;Standard Deviation&quot;) plot.bp(armin,&quot;Min&quot;) plot.bp(armax,&quot;Max&quot;) plot.bp(arskw,&quot;Skews&quot;) plot.bp(arcor,&quot;Lag-1 correlation&quot;) The graphs show a differentiated skew performance, although the fit seems to be equivalent. par(mfrow=c(2,3)) plot.bp(ar.year.stat[,&quot;mean&quot;],&quot;Mean&quot;) plot.bp(ar.year.stat[,&quot;stdev&quot;],&quot;Standard Deviation&quot;) plot.bp(ar.year.stat[,&quot;min&quot;],&quot;Min&quot;) plot.bp(ar.year.stat[,&quot;max&quot;],&quot;Max&quot;) plot.bp(ar.year.stat[,&quot;skew&quot;],&quot;Skews&quot;) plot.bp(ar.year.stat[,&quot;cor&quot;],&quot;Lag-1 correlation&quot;) plot.pdf(xeval,xdensityorig,simpdf) The simulated May PDF is no longer symmetric, as it would be expected from a Gamma Distribution plot.pdf(yeval,year.density,year.pdf) The same effect is depicted in the anual PDF. "],
["nonparametric-seasonal-lag-1-model.html", "Exercise 2 Nonparametric seasonal lag-1 model 2.1 Generate 250 simulations each of same length as the historical data. 2.2 Plot statistics from simulations 2.3 Advantages/disadvantages with a nonparametric approach. **", " Exercise 2 Nonparametric seasonal lag-1 model Fit a nonparametric seasonal lag-1 model and repeat [exercise] 1. You can use either the the K-nn bootstrap technique or LOCFIT/residual resampling and repeat 1. 2.1 Generate 250 simulations each of same length as the historical data. # Load libraries libr=c(&quot;magrittr&quot;,&quot;sm&quot;,&quot;stats&quot;,&quot;moments&quot;) options(warn=1) suppressPackageStartupMessages(lapply(libr, require, character.only = TRUE)) # import and set up flow data flow = read.table( &quot;http://civil.colorado.edu/~balajir/CVEN6833/HWs/HW-3-2018/LeesFerry-monflows-1906-2016.txt&quot;) flow = flow[,2:13] %&gt;% `rownames&lt;-`(flow[,1]) %&gt;% setNames(.,c(&quot;jan&quot;,&quot;feb&quot;,&quot;mar&quot;,&quot;apr&quot;,&quot;may&quot;,&quot;jun&quot;, &quot;jul&quot;,&quot;aug&quot;,&quot;sep&quot;,&quot;oct&quot;,&quot;nov&quot;,&quot;dec&quot;)) %&gt;% {./10^6} # convert AF to MAF flow$year = rowSums(flow) # add year in 13th column head(flow,n=1L) # show values ## jan feb mar apr may jun jul aug ## 1906 0.244314 0.292534 0.678174 1.20464 3.635101 5.014167 2.95046 1.605086 ## sep oct nov dec year ## 1906 1.503159 0.739807 0.503006 0.353312 18.72376 tail(flow,n=1L) ## jan feb mar apr may jun jul ## 2016 0.360703 0.448837 0.67914 1.099567 2.967581 3.910287 1.342044 ## aug sep oct nov dec year ## 2016 0.609946 0.485507 0.546633 0.426289 0.345163 13.2217 # Simulations (innovation defines st. distribution of error) nsim=100 # number of simulations nsim1=nsim+1 nyrs=length(flow[,1]) # years nyrs1 = nyrs-1 N=nyrs*12 # time series for monthly flow armean=matrix(0,nsim,12) #matrices that store the statistics arstdev=matrix(0,nsim,12) arcor=matrix(0,nsim,12) arskw=matrix(0,nsim,12) armax=matrix(0,nsim,12) armin=matrix(0,nsim,12) ar.year.stat=matrix(NA,ncol = 6,nrow = nsim) # year statistics colnames(ar.year.stat) = c(&quot;mean&quot;,&quot;stdev&quot;,&quot;min&quot;,&quot;max&quot;,&quot;skew&quot;,&quot;cor&quot;) # Points where May PDF is evaluated xeval=seq(min(flow$may)-0.25*sd(flow$may), max(flow$may)+0.25*sd(flow$may),length=100) simpdf=matrix(0,nrow=nsim,ncol=100) # Array to store May simulated PDF # Points where anual PDF is evaluated yeval=seq(min(flow$year)-0.25*sd(flow$year), max(flow$year)+0.25*sd(flow$year),length=100) year.pdf=matrix(0,nrow=nsim,ncol=100) # Array to store anual simulated PDF # # The anual flow is modeled using single AR(1) model # ar.year=ar(flow$year,order.max = 1) #AR order 1, MA # Fitting Np-AR-1 model K=round(sqrt(nyrs)) #number of nearest neighbors W= 1:K %&gt;% {1/.} %&gt;% {./sum(.)} %&gt;% cumsum(.) # weight function for (isim in 1:nsim) { i=round(runif(1,2,nyrs)) # initial random year zsim = 1:N # n of monthly flow time series zsim[1] = flow[i,1] # initial flow (Jan of year i) xp = zsim[1] # Previous value initialization # Monthly flow simulations for (j in 2:N) { mo = j%%12 # month we are simulating imon=ifelse(mo==0,12,mo) if (mo != 1){ # if mo = 0 (Dec) data = flow[,1:12] # data is the same as test (Jan - Dec) } else { # Jan data = cbind(flow[2:nyrs,1],flow[1:nyrs1,2:12]) } # if mo = 1 (JAn), 1st col of data will be March, last col will be Feb mo1 = mo-1 if(mo == 0)mo1=11 if(mo == 1)mo1=12 xdist = order(abs(xp - data[,mo1])) # if (mo == 1) { # xdist = order(abs(xp - data[,mo1]))} # if (mo &gt;1) { # xx=rbind(xp, data[,(12-ilag):11]) # xdist = order(as.matrix(dist(xx))[1,2:nyrs+1]) } xx=runif(1,0,1) # generate random number xy=c(xx,W) xx=rank(xy) # get rank with respect to W i1=xdist[xx[1]] # distance order at given rank zsim[j]=data[i1,imon] # select data at given distance xp = zsim[j] # store previous year for next it. } # end j loop simdismon = matrix(zsim, ncol=12, byrow = TRUE) # makes a 12 column matrix with jan thru dec maysim = simdismon[,5] simpdf[isim,]=sm.density(maysim,eval.points=xeval,display=&quot;none&quot;)$estimate # Fill statistics for each month for(j in 1:12){ armean[isim,j]=mean(simdismon[,j]) armax[isim,j]=max(simdismon[,j]) armin[isim,j]=min(simdismon[,j]) arstdev[isim,j]=sd(simdismon[,j]) arskw[isim,j]=skewness(simdismon[,j]) } arcor[isim,1]=cor(simdismon[-nyrs,12],simdismon[2:nyrs,1]) #cor dec-jan for(j in 2:12){ # rest of pairs j1=j-1 arcor[isim,j]=cor(simdismon[,j],simdismon[,j1]) } # Anual flow simulations y.sim = 1:nyrs # n of anual flow time series y.sim[1] = flow[i,&quot;year&quot;] # initial flow (Year i) y.p = y.sim[1] # Previous value initialization y.data=flow$year # dataset is fixed for anual ts. for(j in 2:nyrs){ y.dist = order(abs(y.p - y.data)) i1 = runif(1,0,1) %&gt;% c(.,W) %&gt;% rank(.) %&gt;% {y.dist[.[1]]} y.sim[j]=y.data[i1] # select y.data at given distance y.p = y.sim[j] # store previous year for next it. } # Get anual PDF year.pdf[isim,]=sm.density(y.sim,eval.points= yeval,display=&quot;none&quot;)$estimate # Calculate statistics ar.year.stat[isim,&quot;mean&quot;]=mean(y.sim) ar.year.stat[isim,&quot;max&quot;]=max(y.sim) ar.year.stat[isim,&quot;min&quot;]=min(y.sim) ar.year.stat[isim,&quot;stdev&quot;]=sd(y.sim) ar.year.stat[isim,&quot;skew&quot;]=skewness(y.sim) ar.year.stat[isim,&quot;cor&quot;]=cor(y.sim[-nyrs],y.sim[2:nyrs]) } # end isim loop We add the statistics from historical data in the first row of the tables # Compute statistics from the historical data. obsmean=1:12 obsstdev=1:12 obscor=1:12 obsskw=1:12 obsmax=1:12 obsmin=1:12 for(i in 1:12){ obsmax[i]=max(flow[,i]) obsmin[i]=min(flow[,i]) obsmean[i]=mean(flow[,i]) obsstdev[i]=sd(flow[,i]) obsskw[i]=skewness(flow[,i]) } obscor[1]= cor(flow[-nyrs,12], flow[2:nyrs,1]) for(i in 2:12){ i1=i-1 obscor[i]=cor(flow[,i], flow[,i1]) } # bind the stats of the historic data at the top.. armean=rbind(obsmean,armean) arstdev=rbind(obsstdev,arstdev) arskw=rbind(obsskw,arskw) arcor=rbind(obscor,arcor) armax=rbind(obsmax,armax) armin=rbind(obsmin,armin) # anual flow binding year.stat=c(mean(flow$year),sd(flow$year),min(flow$year), max(flow$year),skewness(flow$year), cor(flow$year[-nyrs],flow$year[2:nyrs])) ar.year.stat = rbind(year.stat,ar.year.stat) 2.2 Plot statistics from simulations Create boxplots of annual and monthly, mean, variance, skew, lag-1 correlation, minimum, maximum and PDFs of May and annual flows. Comment on what you observe and also on why some of the monthly statistics are not captured. # function to plot boxplots with the structure: hist. in first row plot.bp = function(matrix,name){ xmeans=as.matrix(matrix) n=length(xmeans[,1]) xmeans1=as.matrix(xmeans[2:n,]) #the first row is the original data xs=1:12 zz=boxplot(split(xmeans1,col(xmeans1)), plot=F, cex=1.0) zz$names=rep(&quot;&quot;,length(zz$names)) z1=bxp(zz,ylim=range(xmeans),xlab=&quot;&quot;,ylab=&quot;&quot;,cex=1.00) points(z1,xmeans[1,],pch=16, col=&quot;red&quot;) lines(z1,xmeans[1,],pch=16, col=&quot;gray&quot;) title(main=name) } The plots for the statistics of the simulated time series (shown as boxplots) vs. the historical data (shown as points and lines) are reproduced below: par(mfrow=c(3,2)) plot.bp(armean,&quot;Mean&quot;) plot.bp(arstdev,&quot;Standard Deviation&quot;) plot.bp(armin,&quot;Min&quot;) plot.bp(armax,&quot;Max&quot;) plot.bp(arskw,&quot;Skews&quot;) plot.bp(arcor,&quot;Lag-1 correlation&quot;) All the statistics are well fitted with respect the historical data. The anual statistics are similarly represented below: par(mfrow=c(2,3)) plot.bp(ar.year.stat[,&quot;mean&quot;],&quot;Mean&quot;) plot.bp(ar.year.stat[,&quot;stdev&quot;],&quot;Standard Deviation&quot;) plot.bp(ar.year.stat[,&quot;min&quot;],&quot;Min&quot;) plot.bp(ar.year.stat[,&quot;max&quot;],&quot;Max&quot;) plot.bp(ar.year.stat[,&quot;skew&quot;],&quot;Skews&quot;) plot.bp(ar.year.stat[,&quot;cor&quot;],&quot;Lag-1 correlation&quot;) For the anual flow, this is no longer true. Some statistics are not poorly fitted. xdensityorig = flow$may %&gt;% sm.density(.,eval.points=xeval,display=&quot;none&quot;) %&gt;% .$estimate plot.pdf = function(eval,histPDF,simPDF){ xeval = eval plot(xeval,histPDF,pch=&quot;.&quot;,col=&quot;red&quot;,ylim=range(simPDF,histPDF), xlab=&quot;&quot;,ylab = &quot;&quot;) for(i in 1:nsim)lines(xeval,simPDF[i,],col=&#39;lightgrey&#39;,lty=3) lines(xeval,histPDF,lwd=3,col=&quot;red&quot;) title(main=&quot;Historical vs. simulated PDF&quot;) } plot.pdf(xeval,xdensityorig,simpdf) The simulated PDF shows the bimodal behavior, and does not respond to a probabilistic distribution, as it happened to parametric AR. year.density = flow$year %&gt;% sm.density(.,eval.points=yeval, display=&quot;none&quot;) %&gt;% .$estimate plot.pdf(yeval,year.density,year.pdf) Many results are repeated (only 111 values for 100 simulations of 111 time series), creating a crisp PDF. Not realistic. 2.3 Advantages/disadvantages with a nonparametric approach. ** When the dataset is large enough, the fitted PDF and statistics over perform the parametric modelling. When the opposite occurs, many values are repeatedly picked, resulting in biased PDF and statistics. "],
["multivariate-simulation-copulas.html", "Exercise 3 Multivariate Simulation - Copulas 3.1 Fit a Copula to the joint CDF (copula by pairs) 3.2 Simulate from the Copula and invert 3.3 Boxplot the statistics listed in problem 1 and compare with the results from the previous methods 3.4 12 months copula", " Exercise 3 Multivariate Simulation - Copulas Another approach to simulating the monthly streamflow is using Copulas. Fit appropriate marginal PDFs for each monthly streamflow 3.0.1 Data import and setup # Load libraries libr=c(&quot;magrittr&quot;,&quot;sm&quot;,&quot;MASS&quot;,&quot;ks&quot;,&quot;copula&quot;,&quot;moments&quot;) options(warn=1) suppressPackageStartupMessages(lapply(libr, require, character.only = TRUE)) # import and set up flow data flow = read.table( &quot;http://civil.colorado.edu/~balajir/CVEN6833/HWs/HW-3-2018/LeesFerry-monflows-1906-2016.txt&quot;) flow = flow[,2:13] %&gt;% `rownames&lt;-`(flow[,1]) %&gt;% setNames(.,c(&quot;jan&quot;,&quot;feb&quot;,&quot;mar&quot;,&quot;apr&quot;,&quot;may&quot;,&quot;jun&quot;, &quot;jul&quot;,&quot;aug&quot;,&quot;sep&quot;,&quot;oct&quot;,&quot;nov&quot;,&quot;dec&quot;)) %&gt;% {./10^6} # convert AF to MAF head(flow,n=1L) # show values ## jan feb mar apr may jun jul aug ## 1906 0.244314 0.292534 0.678174 1.20464 3.635101 5.014167 2.95046 1.605086 ## sep oct nov dec ## 1906 1.503159 0.739807 0.503006 0.353312 tail(flow,n=1L) ## jan feb mar apr may jun jul ## 2016 0.360703 0.448837 0.67914 1.099567 2.967581 3.910287 1.342044 ## aug sep oct nov dec ## 2016 0.609946 0.485507 0.546633 0.426289 0.345163 3.1 Fit a Copula to the joint CDF (copula by pairs) As a first approach, we will use copula by pairwise comparison (lag-1 model). # Function to fit copula estimator for a pair of time series fit2copula = function(data1,data2){ u = pobs(cbind(data1,data2)) fc=normalCopula(dim=2,disp=&#39;un&#39;) fnc = fitCopula(fc,u) return(fnc) } # Function to generate simulated values from fitted copula sim.copula = function(fnc,data2,N){ cop.sim = rCopula(N,normalCopula(fnc,dim=2,dispstr=&#39;un&#39;)) data.sim = quantile(data2,cop.sim[,2]) # quan.sim = qkde(cop.sim[,2],fhat) return(data.sim) # return(quan.sim) } 3.2 Simulate from the Copula and invert # Simulation paramenters nsim=250 N=length(flow[,1]) # years armean=matrix(0,nsim,12) #matrices to store the statistics arstdev=matrix(0,nsim,12) arcor=matrix(0,nsim,12) arskw=matrix(0,nsim,12) armax=matrix(0,nsim,12) armin=matrix(0,nsim,12) xeval = matrix(0,nrow = 100,ncol = 12) # Points where the PDF is evaluated for(i in 1:12){ xeval[,i]=seq(min(flow[,i])-0.25*sd(flow[,i]), max(flow[,i])+0.25*sd(flow[,i]),length=100) } simpdf = array(0,c(100,12,nsim)) # Array to store simulated PDF xsim = array(0,c(N,12,nsim)) # Array to store simulated val # Simulation initialization parameters ncop = 12 # generate pairs of data to use in copula data1 = data2 = array(NA,c(N,1,ncop)) # data 1 / 2: prev / current month fnc = 1:ncop # fitted normal copulas for every pair for(icop in 1:ncop){ if(icop==1){ data1[-N,1,icop] = flow$dec[-N] # dec of previous year data2[-N,1,icop] = flow$jan[2:N] # jan of next year fnc[icop] = fit2copula(data1[-N,,icop],data2[-N,,icop])@estimate }else{ data1[,1,icop] = flow[,icop-1] # as given data2[,1,icop] = flow[,icop] # as given fnc[icop] = fit2copula(data1[,,icop],data2[,,icop])@estimate } } for(isim in 1:nsim){ # simulation loop for(j in 1:12){ # get each month as copula with previous month if(j==1){ # dec-jan copula xsim[,j,isim]=sim.copula(fnc[j],data2[-N,,j],N) # remove NA year 111 }else{ xsim[,j,isim]=sim.copula(fnc[j],data2[,,j],N) # simulated values } simpdf[,j,isim]=sm.density(xsim[,j,isim], # simulated PDF eval.points=xeval[,j],display=&quot;none&quot;)$estimate # fill statistics armean[isim,j]=mean(xsim[,j,isim]) armax[isim,j]=max(xsim[,j,isim]) armin[isim,j]=min(xsim[,j,isim]) arstdev[isim,j]=sd(xsim[,j,isim]) arskw[isim,j]=skewness(xsim[,j,isim]) if(j&gt;2)arcor[isim,j]=cor(xsim[,j,isim],xsim[,j-1,isim]) } arcor[isim,1]=cor(xsim[-N,12,isim],xsim[2:N,1,isim]) # print(isim) } We now add the statistics from the original dataset and bind it with the simulation st. # Compute statistics from the historical data. obsmean=1:12 obsstdev=1:12 obscor=1:12 obsskw=1:12 obsmax=1:12 obsmin=1:12 for(i in 1:12){ obsmax[i]=max(flow[,i]) obsmin[i]=min(flow[,i]) obsmean[i]=mean(flow[,i]) obsstdev[i]=sd(flow[,i]) obsskw[i]=skewness(flow[,i]) } obscor[1]= cor(flow[-N,12], flow[2:N,1]) for(i in 2:12){ obscor[i]=cor(flow[,i], flow[,i-1]) } # bind the stats of the historic data at the top.. armean=rbind(obsmean,armean) arstdev=rbind(obsstdev,arstdev) arskw=rbind(obsskw,arskw) arcor=rbind(obscor,arcor) armax=rbind(obsmax,armax) armin=rbind(obsmin,armin) 3.3 Boxplot the statistics listed in problem 1 and compare with the results from the previous methods We repeat the code from problem 1 to do so. # function to plot boxplots with the structure: hist. in first row plot.bp = function(matrix,name){ xmeans=as.matrix(matrix) n=length(xmeans[,1]) xmeans1=as.matrix(xmeans[2:n,]) #the first row is the original data xs=1:12 zz=boxplot(split(xmeans1,col(xmeans1)), plot=F, cex=1.0) zz$names=rep(&quot;&quot;,length(zz$names)) z1=bxp(zz,ylim=range(xmeans),xlab=&quot;&quot;,ylab=&quot;&quot;,cex=1.00) points(z1,xmeans[1,],pch=16, col=&quot;red&quot;) lines(z1,xmeans[1,],pch=16, col=&quot;gray&quot;) title(main=name) } par(mfrow=c(3,2)) plot.bp(armean,&quot;Mean&quot;) plot.bp(arstdev,&quot;Standard Deviation&quot;) plot.bp(armin,&quot;Min&quot;) plot.bp(armax,&quot;Max&quot;) plot.bp(arskw,&quot;Skews&quot;) plot.bp(arcor,&quot;Lag-1 correlation&quot;) As observed, mean, st.dev, max and skews are well fit. Min values are overestimated, and lag-1 is not captured. In general, the statics are better than the ones using autoregressive models. xdensityorig = matrix (0,nrow = 100,ncol = 12) #initialize original PDF for(j in 1:12){ # obtain original PDF xdensityorig[,j] = flow[,j] %&gt;% sm.density(.,eval.points=xeval[,j],display=&quot;none&quot;) %&gt;% .$estimate } plot.pdf = function(eval,histPDF,simPDF,title){ xeval = eval plot(xeval,histPDF,pch=&quot;.&quot;,col=&quot;red&quot;,ylim=range(simPDF,histPDF), xlab=&quot;&quot;,ylab = &quot;&quot;) for(i in 1:nsim)lines(xeval,simPDF[,i],col=&#39;lightgrey&#39;,lty=3) lines(xeval,histPDF,lwd=3,col=&quot;red&quot;) title(main=title) } par(mfrow=c(4,3)) par(mar=c(2,2,2,2)) for(j in 1:12){ plot.pdf(xeval[,j],xdensityorig[,j],simpdf[,j,],colnames(flow[j])) } The simulated PDF do not respond to a probabilistic distribution, sitting closely around the empirical PDF. The result is more precise that the one using autoregressive models. 3.4 12 months copula Now we will use the full copula between all months. u = pobs(flow) # convert to pseudo-observations fc12=normalCopula(dim=12,disp=&#39;un&#39;) # normal copula (66) fnc12 = fitCopula(fc12,u) # estimate from copula dat_sim = array(0,c(N,12,nsim)) cop_pdf = array(0,c(100,12,nsim)) carmean=matrix(0,nsim,12) #matrices to store the statistics carstdev=matrix(0,nsim,12) carcor=matrix(0,nsim,12) carskw=matrix(0,nsim,12) carmax=matrix(0,nsim,12) carmin=matrix(0,nsim,12) for(isim in 1:nsim){ cop_sim = rCopula(N,normalCopula(fnc12@estimate,dim=12,dispstr=&#39;un&#39;)) for(j in 1:12){ dat_sim[,j,isim] = quantile(flow[,j],cop_sim[,j]) cop_pdf[,j,isim]=sm.density(dat_sim[,j,isim], # simulated PDF eval.points=xeval[,j],display=&quot;none&quot;)$estimate # fill statistics carmean[isim,j]=mean(dat_sim[,j,isim]) carmax[isim,j]=max(dat_sim[,j,isim]) carmin[isim,j]=min(dat_sim[,j,isim]) carstdev[isim,j]=sd(dat_sim[,j,isim]) carskw[isim,j]=skewness(dat_sim[,j,isim]) if(j&gt;2)carcor[isim,j]=cor(dat_sim[,j,isim],dat_sim[,j-1,isim]) } carcor[isim,1]=cor(dat_sim[-N,12,isim],dat_sim[2:N,1,isim]) # print(isim) } # bind the stats of the historic data at the top.. carmean=rbind(obsmean,carmean) carstdev=rbind(obsstdev,carstdev) carskw=rbind(obsskw,carskw) carcor=rbind(obscor,carcor) carmax=rbind(obsmax,carmax) carmin=rbind(obsmin,carmin) par(mfrow=c(3,2)) plot.bp(carmean,&quot;Mean&quot;) plot.bp(carstdev,&quot;Standard Deviation&quot;) plot.bp(carmin,&quot;Min&quot;) plot.bp(carmax,&quot;Max&quot;) plot.bp(carskw,&quot;Skews&quot;) plot.bp(carcor,&quot;Lag-1 correlation&quot;) The results are at least as good as the copula by pairs. Also, the lag-1 correlation is captured (with the exception of jan and feb). par(mfrow=c(4,3)) par(mar=c(2,2,2,2)) for(j in 1:12){ plot.pdf(xeval[,j],xdensityorig[,j],cop_pdf[,j,],colnames(flow[j])) } The simulated PDF are also really close to the empirical PDF, being able to mimic the multimodal behavior of February, May, July, etc. "]
]
