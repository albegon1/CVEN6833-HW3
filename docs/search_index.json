[
["non-stationary-time-series-hidden-markov-model.html", "Exercise 4 Non stationary time series - Hidden Markov Model 4.1 Fit a best HMM for the May Lees Ferry streamflow 4.2 Generate 250 simulations from the fitted HMM 4.3 Boxplot the resulting statistics 4.4 Fit an GLM for the state series 4.5 Use the state GLM to simulate flows from the component distribution", " Exercise 4 Non stationary time series - Hidden Markov Model Another way to simulate a time series is using Hidden Markov Model (Markov Chain + resampling). # libraries libr=c(&quot;HiddenMarkov&quot;,&quot;ggplot2&quot;,&quot;data.table&quot;,&quot;ggthemes&quot;, &quot;magrittr&quot;,&quot;sm&quot;,&quot;moments&quot;,&quot;MASS&quot;,&quot;leaps&quot;) options(warn=1) suppressPackageStartupMessages(lapply(libr, require, character.only = TRUE)) ## Load flow data flow = read.table( &quot;http://civil.colorado.edu/~balajir/CVEN6833/HWs/HW-3-2018/LeesFerry-monflows-1906-2016.txt&quot;) flow = flow[,2:13] %&gt;% `rownames&lt;-`(flow[,1]) %&gt;% setNames(.,c(&quot;jan&quot;,&quot;feb&quot;,&quot;mar&quot;,&quot;apr&quot;,&quot;may&quot;,&quot;jun&quot;, &quot;jul&quot;,&quot;aug&quot;,&quot;sep&quot;,&quot;oct&quot;,&quot;nov&quot;,&quot;dec&quot;)) %&gt;% {./10^6} # convert AF to MAF x = flow$may ## select the May month flows 4.1 Fit a best HMM for the May Lees Ferry streamflow The code below fits HMM models of orders 2 through 6 and calculates the AIC for each. Best order is the one with the least value of AIC. ## Fit HMM models of orders 2 through 6. Obtain the AIC for each ## Best order is the one with the least value of AIC. family &lt;- &quot;gamma&quot; # underlying distribution for hmm discrete &lt;- FALSE aic1=c() for(imodel in 2:6){ m &lt;- imodel #model order to fit stationary &lt;- F # use a stationary distribution of mixtures # different initial condition types when family == &quot;norm&quot; ic &lt;- &quot;same.sd&quot;#c(&quot;same.sd&quot;,&quot;same.both&quot;,&quot;both.diff&quot;) fd.name &lt;- ifelse(family == &quot;norm&quot;, &quot;normal&quot;, family) Pi &lt;- Pi_init(m) # T.P.M. delta &lt;- delta_init(m) pars &lt;- get.named.parlist(x, m, fd.name, lower=.0, ic)#,start=list(shape1=2,shape2=2)) # set up the model hmm &lt;- dthmm(x, Pi=Pi, delta=delta, family, pars, nonstat=!stationary, discrete = discrete) sink(&quot;p.4.hmm.fit&quot;) if(imodel &lt; 2){ hmm &lt;- BaumWelch(hmm, bwcontrol(maxiter = 1000, posdiff=TRUE,converge = expression(diff &gt; tol))) } else { hmm &lt;- BaumWelch(hmm, bwcontrol(maxiter = 1000, tol = 1e-08)) } sink() # get the hidden states from the fitted model # Global decoding. To get the probability of being in a state: hmm$u decoding &lt;- Viterbi(hmm) # get AIC aic &lt;- AIC(hmm) aic1=c(aic1,aic) } We select the hmm model with the lowest AIC. In this case, this happens to be of order 2. We rerun the HMM for best order (m=2). Below is the the model summary and the best state sequence resulting from it. ## Get the best order bestorder = order(aic1)[1] +1 ## Fit the model for this best order m &lt;- bestorder #model order to fit stationary &lt;- F # use a stationary distribution of mixtures # different initial condition types when family == &quot;norm&quot; ic &lt;- &quot;same.sd&quot;#c(&quot;same.sd&quot;,&quot;same.both&quot;,&quot;both.diff&quot;) fd.name &lt;- ifelse(family == &quot;norm&quot;, &quot;normal&quot;, family) Pi &lt;- Pi_init(m) # T.P.M. delta &lt;- delta_init(m) pars &lt;- get.named.parlist(x, m, fd.name, lower=.0, ic)#,start=list(shape1=2,shape2=2)) # set up the model hmm &lt;- dthmm(x, Pi=Pi, delta=delta, family, pars, nonstat=!stationary, discrete = discrete) sink(&quot;p.4.best.hmm&quot;) hmm &lt;- BaumWelch(hmm, bwcontrol(maxiter = 1000, tol = 1e-08)) sink() # end hidding output decoding &lt;- Viterbi(hmm) The summary of the resulting model is shown below: print(summary(hmm)) ## $delta ## [1] 1.122144e-104 1.000000e+00 ## ## $Pi ## [,1] [,2] ## [1,] 0.6585751 0.3414249 ## [2,] 0.2953837 0.7046163 ## ## $nonstat ## [1] TRUE ## ## $distn ## [1] &quot;gamma&quot; ## ## $pm ## $pm$rate ## [1] 2.974823 4.062193 ## ## $pm$shape ## [1] 6.992025 15.203073 ## ## ## $discrete ## [1] FALSE ## ## $n ## [1] 111 cat(&#39;Model order:&#39;,m,&#39;\\n&#39;) ## Model order: 2 p &lt;- ggplot_stationary_hmm(hmm,.5) print(p) ## Warning: Removed 1 rows containing missing values (geom_bar). state1=ifelse(decoding==1,2,NA) state2=ifelse(decoding==2,1,NA) plot(flow$may-mean(flow$may)+1.5,type=&quot;l&quot;,ylab=&quot;&quot;, main=&quot;Modified May flows and states (supperposed)&quot;) points(state1,col=&#39;blue&#39;) points(state2,col=&#39;red&#39;) legend(&quot;topright&quot;,legend=c(&quot;state 1&quot;,&quot;state 2&quot;),col=c(&quot;red&quot;,&quot;blue&quot;),pch=1) 4.2 Generate 250 simulations from the fitted HMM This involves generating the state sequence from the transition probability matrix and resampling flows from the corresponding component distribution. # Now simulate # First simulate a sequence of states from the TPM # simulate from the transition probability N = length(x) nsim = 250 nprob = length(decoding[decoding == 1])/N delta1=c(nprob,1-nprob) #stationary probability zsim = mchain(NULL,hmm$Pi,delta=delta1) may.sim = matrix(0,nrow=nsim,ncol=N) # Points where May PDF is evaluated xeval=seq(min(flow$may)-0.25*sd(flow$may), max(flow$may)+0.25*sd(flow$may),length=100) sim.pdf=matrix(0,nrow=nsim,ncol=100) # Array to store May simulated PDF may.stat=matrix(NA,ncol = 6,nrow = nsim) # year statistics colnames(may.stat) = c(&quot;mean&quot;,&quot;stdev&quot;,&quot;min&quot;,&quot;max&quot;,&quot;skew&quot;,&quot;cor&quot;) for(isim in 1:nsim){ zsim = simulate(zsim,nsim=N) ## now simulate the flows from the corresponding PDF flowsim = c() for(i in 1:N){ if(zsim$mc[i] == 1)xx=rgamma(1,shape=hmm$pm$shape[1], scale=1/hmm$pm$rate[1]) if(zsim$mc[i] == 2)xx=rgamma(1,shape=hmm$pm$shape[2], scale=1/hmm$pm$rate[2]) flowsim=c(flowsim,xx) } may.sim[isim,]=flowsim sim.pdf[isim,]=sm.density(flowsim,eval.points=xeval, display=&quot;none&quot;)$estimate # fill statistics may.stat[isim,&quot;mean&quot;]=mean(flowsim) may.stat[isim,&quot;max&quot;]=max(flowsim) may.stat[isim,&quot;min&quot;]=min(flowsim) may.stat[isim,&quot;stdev&quot;]=sd(flowsim) may.stat[isim,&quot;skew&quot;]=skewness(flowsim) may.stat[isim,&quot;cor&quot;]=cor(flowsim[-N],flowsim[2:N]) } The statistics from the historical data is added in the first row of the statistics matrix. # Compute statistics from the historical data. obs=1:6 obs[1]=mean(flow$may) obs[2]=sd(flow$may) obs[3]=min(flow$may) obs[4]=max(flow$may) obs[5]=skewness(flow$may) obs[6]=cor(flow$may[-N],flow$may[2:N]) # bind the stats of the historic data at the top.. may.stat=rbind(obs,may.stat) 4.3 Boxplot the resulting statistics We include the mean, variance, skew, lag-1 correlation, minimum, maximum and PDF from the simulations with the corresponding values from the historical data plotted on them. # function to plot boxplots with the structure: hist. in first row plot.bp = function(matrix,name){ xmeans=as.matrix(matrix) n=length(xmeans[,1]) xmeans1=as.matrix(xmeans[2:n,]) #the first row is the original data xs=1:12 zz=boxplot(split(xmeans1,col(xmeans1)), plot=F, cex=1.0) zz$names=rep(&quot;&quot;,length(zz$names)) z1=bxp(zz,ylim=range(xmeans),xlab=&quot;&quot;,ylab=&quot;&quot;,cex=1.00) points(z1,xmeans[1,],pch=16, col=&quot;red&quot;) lines(z1,xmeans[1,],pch=16, col=&quot;gray&quot;) title(main=name) } par(mfrow=c(2,3)) plot.bp(may.stat[,&quot;mean&quot;],&quot;Mean&quot;) plot.bp(may.stat[,&quot;stdev&quot;],&quot;Standard Deviation&quot;) plot.bp(may.stat[,&quot;min&quot;],&quot;Min&quot;) plot.bp(may.stat[,&quot;max&quot;],&quot;Max&quot;) plot.bp(may.stat[,&quot;skew&quot;],&quot;Skews&quot;) plot.bp(may.stat[,&quot;cor&quot;],&quot;Lag-1 correlation&quot;) The model is able to represent accurately all statistics, including lag-1 correlation. 4.4 Fit an GLM for the state series Instead of simulating the flows from a “static” state sequence, the goal is to simulate the state as a prediction from a best logistic GLM. enso=read.table(&quot;C:/Users/alexb/Google Drive/CVEN 6833 ADAT/zz Homeworks/HW3/enso.txt&quot;) amo=read.table(&quot;C:/Users/alexb/Google Drive/CVEN 6833 ADAT/zz Homeworks/HW3/amo.txt&quot;) pdo=read.table(&quot;C:/Users/alexb/Google Drive/CVEN 6833 ADAT/zz Homeworks/HW3/pdo.txt&quot;) X = data.frame(decoding[-N]-1,enso[-N,],amo[-N,],pdo[-N,]) colnames(X) = c(&quot;ts1&quot;,&quot;enso&quot;,&quot;amo&quot;,&quot;pdo&quot;) Y = decoding[-1]-1 links = c(&quot;logit&quot;, &quot;probit&quot;, &quot;cauchit&quot;,&quot;log&quot;,&quot;cloglog&quot;) comb=leaps(X,Y, nbest=40,method=&quot;adjr2&quot;)$which aic &lt;- matrix(1e6,ncol=length(links),nrow = length(comb[,1])) colnames(aic) = links[1:length(links)] for(k in 1:length(comb[,1])){ xx = X[,comb[k,]] %&gt;% as.data.frame(.) for(i in 1:length(links)){ zz=try(glm(Y ~ ., data=xx, family = binomial(link=links[i]), maxit=500),silent=TRUE) if(class(zz)[1]!=&quot;try-error&quot;)aic[k,i]=zz$aic[1] } } print(aic) ## logit probit cauchit log cloglog ## [1,] 125.3869 125.3869 125.3869 125.3869 125.3869 ## [2,] 146.9211 146.8480 147.3203 145.5355 146.4292 ## [3,] 148.3173 148.4183 147.6240 1000000.0000 148.6837 ## [4,] 151.5616 151.5576 151.5843 151.5075 151.5440 ## [5,] 124.8050 124.6801 125.4507 1000000.0000 124.3818 ## [6,] 125.5837 125.6196 125.6204 1000000.0000 125.7163 ## [7,] 127.1229 127.1318 127.0643 1000000.0000 127.2388 ## [8,] 146.4187 146.4280 146.2500 1000000.0000 146.2306 ## [9,] 148.7136 148.6357 149.1384 1000000.0000 148.1738 ## [10,] 150.2624 150.3579 149.5969 1000000.0000 150.5938 ## [11,] 125.5740 125.5788 125.7137 1000000.0000 125.6044 ## [12,] 126.6695 126.5771 127.1292 1000000.0000 126.3762 ## [13,] 127.5618 127.5892 127.6183 1000000.0000 127.6096 ## [14,] 148.3169 148.3151 148.2090 1000000.0000 148.1186 ## [15,] 127.5421 127.5283 127.7116 1000000.0000 127.4138 index = which(aic == min(aic), arr.ind = TRUE) print( sprintf(&quot;Choosing the GLM which minimizes AIC for binomial family: %s link function and %s covariates&quot;,links[index[,&quot;col&quot;]], paste(colnames(X)[comb[index[,&quot;row&quot;],]],collapse = &#39;, &#39;))) ## [1] &quot;Choosing the GLM which minimizes AIC for binomial family: cloglog link function and ts1, amo covariates&quot; state.glm = glm(Y ~ ., data=X[,comb[index[,&quot;row&quot;],]], family = binomial(link=links[index[,&quot;col&quot;]])) summary(state.glm) ## ## Call: ## glm(formula = Y ~ ., family = binomial(link = links[index[, &quot;col&quot;]]), ## data = X[, comb[index[, &quot;row&quot;], ]]) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.0521 -0.8416 0.4986 0.7478 1.7263 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -0.9698 0.2798 -3.466 0.000528 *** ## ts1 1.4190 0.3205 4.427 9.55e-06 *** ## amo -1.0552 0.5872 -1.797 0.072305 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 148.06 on 109 degrees of freedom ## Residual deviance: 118.38 on 107 degrees of freedom ## AIC: 124.38 ## ## Number of Fisher Scoring iterations: 6 ENSO and PDO resulted to be insignificant covariates for the logistic regression. We tried to lag them with respect to the prediction year without success. 4.5 Use the state GLM to simulate flows from the component distribution X.new = X[,comb[index[,&quot;row&quot;],]] p1 = 1 - sum(round(state.glm$fitted.values))/length(state.glm$fitted.values) state = 1:N # init. state state.p1 = 1:nsim # store p1 may.sim.glm = matrix(0,nrow=nsim,ncol=N) sim.pdf.glm = matrix(0,nrow=nsim,ncol=100) # Array to store May simulated PDF may.stat.glm=matrix(NA,ncol = 6,nrow = nsim) # statistics colnames(may.stat.glm) = c(&quot;mean&quot;,&quot;stdev&quot;,&quot;min&quot;,&quot;max&quot;,&quot;skew&quot;,&quot;cor&quot;) # simulation for(isim in 1:nsim){ # for(j in 2:N)state[j]=round(predict(state.glm,newdata = data.frame(ts1=state[j-1],amo = amo[j-1,1]))) for(j in 1:N){ if(j==1){ state[1]=ifelse(runif(1)&lt;p1,1,2) }else{ state[j]=ifelse(runif(1)&gt;state.glm$fitted.values[j-1],1,2) } if(state[j]==1){ may.sim.glm[isim,j]=rgamma(1,shape = hmm$pm$shape[1],hmm$pm$rate[1]) }else{ may.sim.glm[isim,j]=rgamma(1,shape = hmm$pm$shape[2],hmm$pm$rate[2]) } } state.p1[isim] = 1 - sum((state-1))/length(state) sim.pdf.glm[isim,]=sm.density(may.sim.glm[isim,], eval.points=xeval,display=&quot;none&quot;)$estimate # fill statistics may.stat.glm[isim,&quot;mean&quot;]=mean(may.sim.glm[isim,]) may.stat.glm[isim,&quot;max&quot;]=max(may.sim.glm[isim,]) may.stat.glm[isim,&quot;min&quot;]=min(may.sim.glm[isim,]) may.stat.glm[isim,&quot;stdev&quot;]=sd(may.sim.glm[isim,]) may.stat.glm[isim,&quot;skew&quot;]=skewness(may.sim.glm[isim,]) may.stat.glm[isim,&quot;cor&quot;]=cor(may.sim.glm[isim,-N],may.sim.glm[isim,2:N]) } # bind the stats of the historic data at the top.. may.stat.glm=rbind(obs,may.stat.glm) par(mfrow=c(2,3)) plot.bp(may.stat.glm[,&quot;mean&quot;],&quot;Mean&quot;) plot.bp(may.stat.glm[,&quot;stdev&quot;],&quot;Standard Deviation&quot;) plot.bp(may.stat.glm[,&quot;min&quot;],&quot;Min&quot;) plot.bp(may.stat.glm[,&quot;max&quot;],&quot;Max&quot;) plot.bp(may.stat.glm[,&quot;skew&quot;],&quot;Skews&quot;) plot.bp(may.stat.glm[,&quot;cor&quot;],&quot;Lag-1 correlation&quot;) xdensityorig = flow$may %&gt;% sm.density(.,eval.points=xeval,display=&quot;none&quot;) %&gt;% .$estimate plot.pdf = function(eval,histPDF,simPDF){ xeval = eval plot(xeval,histPDF,pch=&quot;.&quot;,col=&quot;red&quot;,ylim=range(simPDF,histPDF), xlab=&quot;&quot;,ylab = &quot;&quot;) for(i in 1:nsim)lines(xeval,simPDF[i,],col=&#39;lightgrey&#39;,lty=3) lines(xeval,histPDF,lwd=3,col=&quot;red&quot;) title(main=&quot;Historical vs. simulated PDF&quot;) } plot.pdf(xeval,xdensityorig,sim.pdf) plot.pdf(xeval,xdensityorig,sim.pdf.glm) # source functions # takend from &quot;http://civil.colorado.edu/~balajir/CVEN6833/R-sessions/session3/files-4HW3/lib.R&quot; Pi_init &lt;- function(n,type=&#39;uniform&#39;){ matrix(rep(1/n,n^2),n)} delta_init &lt;- function(n, type=&#39;uniform&#39;){ d &lt;- rnorm(n)^2 d/sum(d)} ntile.ts &lt;- function(x, n, limit.type = &#39;prob&#39;, tie = 1, altobs = NULL ){ # returns an integer vector corresponding to n states broken by equal # probability or equal distance # limit &lt;- if(limit.type == &#39;prob&#39;) quantile(x,seq(0,1,1/n)) else if(limit.type == &#39;equal&#39;) seq(min(x),max(x),by=diff(range(x))/n) if(!is.null(altobs)) limit &lt;- quantile(altobs,seq(0,1,1/n)) b &lt;- integer(length(x)) for(i in 1:(n+1)){ filter &lt;- if(tie == 1) x &gt;= limit[i] &amp; x &lt;= limit[i+1] else x &gt; limit[i] &amp; x &lt;= limit[i+1] #only need to set the 1&#39;s because b is already 0&#39;s b[filter] &lt;- as.integer(i-1) } if(class(x) == &#39;ts&#39;) return(ts(b,start=start(x),end=end(x))) else return(b) } get.named.parlist &lt;- function(x,m,dist,ic,...){ require(MASS) fit &lt;- fitdistr(x,dist,...) np &lt;- length(fit$estimate) pars &lt;- vector(&#39;list&#39;,np) names(pars) &lt;- names(fit$estimate) init &lt;- lapply(fit$estimate,max) names(init) &lt;- names(fit$estimate) for(j in 1:m){ #print(j) #browser() #browser() this.fit &lt;- fitdistr(x[ntile.ts(x,m) == (j-1)],dist,init,...) #for(k in 1:np) # pars[[k]][j] &lt;- this.fit$estimate[k] for(k in 1:np) pars[[k]][j] &lt;- fit$estimate[k] if(dist == &#39;normal&#39;){ if(ic == &#39;same.both&#39;){ pars[[k]][j] &lt;- mean(x) pars[[k]][j] &lt;- sd(x) } else if( ic == &#39;same.sd&#39;){ pars[[k]][j] &lt;- mean(x[ntile.ts(x,m) == (j-1)]) pars[[k]][j] &lt;- sd(x) }else{ pars[[k]][j] &lt;- mean(x[ntile.ts(x,m) == (j-1)]) pars[[k]][j] &lt;- sd(x[ntile.ts(x,m) == (j-1)]) } } } pars } AIC.dthmm &lt;- function(x){ ## Return the Akaieke Information criterion value for a fitted discrete ## time hidden markov model from the HiddenMarkov package # Model order m &lt;- length(x$delta) # Log Liklihood value LL &lt;- x$LL # number of parameters p &lt;- m+m^2 # AIC -2*LL + 2*p } ggplot_stationary_hmm &lt;- function(x,binwidth=NULL,res=1000,cols=NULL,...){ m &lt;- length(x$delta) dens &lt;- matrix(0,nrow=m+1,ncol=res) r &lt;- extendrange(x$x,f=.05) xrange &lt;- seq(r[1],r[2],len=res) delta &lt;- statdist(x$Pi) if(is.null(binwidth)) binwidth &lt;- diff(range(x$x))/8 for(i in 1:m){ if(x$distn == &#39;gamma&#39;){ dens[i,] &lt;- delta[i]*dgamma(xrange,shape=x$pm$shape[i],rate=x$pm$rate[i]) }else if(x$distn == &#39;norm&#39;){ dens[i,] &lt;- delta[i]*dnorm(xrange,mean=x$pm$mean[i],sd=x$pm$sd[i]) }else{ stop(&#39;Distribution not supported&#39;) } dens[m+1,] &lt;- dens[m+1,] + dens[i,] } p &lt;- ggplot()+ geom_histogram(data=data.frame(x=as.vector(x$x)),aes(x=x,y=..density..), binwidth=binwidth,fill=&#39;white&#39;,color=&#39;black&#39;)+ theme_bw() dt &lt;- data.table(x=numeric(0),y=numeric(0), state=integer(0)) for(i in 1:m) dt &lt;- rbind(dt, data.table(x=xrange,y=dens[i,], state=i)) dt$state &lt;- factor(dt$state) p &lt;- p + geom_line(data=dt,aes(x=x,y=y,color=state)) + geom_line(data=data.frame(x=xrange,y=dens[m+1,]),aes(x=x,y=y),color=&#39;black&#39;,size=1) + scale_color_tableau() + scale_x_continuous(limits=r) p } statdist &lt;- function(tpm){ m &lt;- nrow(tpm) ones &lt;- rbind(rep(1,m)) I &lt;- diag(rep(1,m)) U &lt;- matrix(rep(1,m^2),m) as.vector(ones %*% solve(I - tpm + U)) } "]
]
